{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import numpy as np\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from typing import Set, Any\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential # Tells you which is the backend used (i.e. Tensorflow)\n",
    "from keras.layers import Dense  # The same Keras code is used for each backend.\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df = ps.sqldf(\"\"\"select * from df order by dateval asc\"\"\")\n",
    "df = df.drop(\"dateval\",axis=1)\n",
    "df['log_y_tomorrow'] = df['log_y'].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(\"log_y_tomorrow\", axis=1).values\n",
    "y = df[\"log_y_tomorrow\"].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train=df.sample(frac=0.8,random_state=200)\n",
    "test=df.drop(train.index)\n",
    "X_train, y_train, X_test, y_test = train.drop([\"log_y_tomorrow\"], axis=1), \\\n",
    "train['log_y_tomorrow'], \\\n",
    "test.drop([\"log_y_tomorrow\"], axis=1), \\\n",
    "test['log_y_tomorrow']\n",
    "\n",
    "y = y_train\n",
    "X = X_train\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "select_top_20 = SelectKBest(score_func=chi2, k = 5)\n",
    "fit = select_top_20.fit(scaled_X,y.astype(int))\n",
    "features = fit.transform(X)\n",
    "mask = select_top_20.get_support()\n",
    "selected_best_features = X.columns[mask]\n",
    "\n",
    "from pandas import DataFrame\n",
    "from typing import Set, Any\n",
    "def remove_others(df: DataFrame, columns: Set[Any]):\n",
    "    cols_total: Set[Any] = set(df.columns)\n",
    "    diff: Set[Any] = cols_total - columns\n",
    "    df.drop(diff, axis=1, inplace=True)\n",
    "remove_others(X_train, set(selected_best_features))\n",
    "remove_others(X_test, set(selected_best_features))\n",
    "\n",
    "\n",
    "num_features = X_train.shape[1] - 1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=num_features)\n",
    "pca.fit(X_train)\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "count = 1\n",
    "n_components = None\n",
    "for k in var1:\n",
    "    if k > 80:\n",
    "        n_components = count\n",
    "        break\n",
    "    count += 1  \n",
    "pca = PCA(n_components=n_components)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# execute_model(model_number=1, X_train=X_train, \\\n",
    "#              X_test=X_test, y_train=y_train, \\\n",
    "#              y_test=y_test, num_features=num_features[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_y', '2379_US_4497_5_X1.Value', '2379_US_4497_5_X2.Value',\n",
       "       '2379_US_4497_5_X3.Value', '2379_US_4497_5_X4.Value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240    14.194773\n",
       "711    12.574559\n",
       "45     11.185762\n",
       "410    13.118915\n",
       "324    12.505199\n",
       "818    11.110685\n",
       "543    14.102125\n",
       "221    13.604109\n",
       "207    14.094351\n",
       "806    11.395099\n",
       "316    13.956078\n",
       "182    14.337670\n",
       "511    14.250650\n",
       "894    12.164313\n",
       "322    12.898384\n",
       "204    13.406390\n",
       "235    14.374567\n",
       "285    13.139335\n",
       "114    10.621035\n",
       "910     0.000000\n",
       "407    13.198745\n",
       "508    14.449211\n",
       "344    12.630494\n",
       "781    11.859454\n",
       "412    12.016956\n",
       "136    10.930120\n",
       "377    13.467300\n",
       "646    13.094696\n",
       "259    12.814068\n",
       "329    12.656658\n",
       "         ...    \n",
       "367    13.811103\n",
       "775    13.353129\n",
       "624    13.721800\n",
       "331    12.535272\n",
       "566    13.002412\n",
       "292    11.207602\n",
       "817    11.270497\n",
       "102    10.528704\n",
       "220    13.197744\n",
       "542    13.907001\n",
       "205    13.252231\n",
       "319    13.514726\n",
       "132    11.374341\n",
       "426    11.891704\n",
       "405    13.386750\n",
       "223    13.300920\n",
       "191    14.110203\n",
       "586    13.302885\n",
       "545    13.583573\n",
       "386    13.872203\n",
       "369    13.781121\n",
       "308    11.320178\n",
       "414    11.682348\n",
       "728    13.791771\n",
       "823    11.270115\n",
       "21     11.924957\n",
       "507    14.146325\n",
       "485    12.094783\n",
       "10     12.261056\n",
       "554    13.679407\n",
       "Name: log_y_tomorrow, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127e8b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models = []\n",
    "models.append((\"LR\",LogisticRegression()))\n",
    "models.append((\"KNN\",KNeighborsRegressor()))\n",
    "models.append((\"DT\",DecisionTreeRegressor()))\n",
    "models.append((\"SVR\",SVR()))\n",
    "models.append((\"AdaBoost\",AdaBoostRegressor(n_estimators=500, random_state=2)))\n",
    "models.append((\"RandomForestRegressor\",RandomForestRegressor(n_estimators = 1000, max_features=\"log2\", min_samples_leaf=5, criterion=\"mse\", \n",
    "                                        bootstrap = True,random_state=2)))\n",
    "models.append((\"XGBRegressor\",make_pipeline(\n",
    "    StackingEstimator(estimator=RidgeCV()),\n",
    "    XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=13, n_estimators=100, nthread=1, subsample=0.55)\n",
    ")))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=5, random_state=22)\n",
    "    cv_result = cross_val_score(model,X_train,y_train.astype(int), cv = kfold, scoring='neg_mean_squared_error')\n",
    "    names.append(name)\n",
    "    results.append(cv_result)\n",
    "ax = sns.boxplot(data=results)\n",
    "ax.set_xticklabels(names, rotation=30)\n",
    "y_prediction = np.zeros(len(y_test))\n",
    "y_prediction.fill(y_train.mean())\n",
    "baseline_mse = mean_squared_error(y_test, y_prediction)\n",
    "# plt.plot(np.linspace(-20,120,1000), [-1*baseline_mse]*1000, 'r')\n",
    "plt.title(\"Model (Baseline model is {})\".format(baseline_mse))\n",
    "plt.savefig('Models_Results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.21597537e-01,  -8.22009301e-01,   1.63746963e-01,\n",
       "         -4.45233492e-01],\n",
       "       [ -3.26568719e-03,  -4.34686026e-01,   1.63572518e+00,\n",
       "          3.64235762e-01],\n",
       "       [  3.70675592e+00,   1.78383913e+00,  -6.34549627e-01,\n",
       "         -4.46744839e-01],\n",
       "       ..., \n",
       "       [ -1.20607267e+00,  -3.09041986e-02,   3.98602529e-01,\n",
       "         -5.27312800e-01],\n",
       "       [  4.48078563e+00,   5.86566480e-01,  -3.70382981e-01,\n",
       "          8.16984167e-02],\n",
       "       [  3.92819871e-02,  -1.44335581e+00,  -5.46103221e-01,\n",
       "          5.35473153e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.333838190665\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential # Tells you which is the backend used (i.e. Tensorflow)\n",
    "from keras.layers import Dense  # The same Keras code is used for each backend.\n",
    "from keras.optimizers import Adam, SGD\n",
    "model = Sequential() # linear stack of layers\n",
    "model.add(Dense(1, input_shape=(4,))) # 1 output, 1 input\n",
    "model.summary() # bias is included in parameter count\n",
    "model.compile(Adam(lr=0.8), 'mean_squared_error') # Important - Builds the model\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0) # first to input and output\n",
    "y_pred = model.predict(X_test) # Get a y_prediction for each X\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# for i in range(1, 8):\n",
    "#     lag = range(0,31)\n",
    "#     df_acf = []\n",
    "#     for l in lag:\n",
    "#         df_acf.append(df['log_y_tomorrow'].autocorr(l))\n",
    "#     plt.figure(figsize=(5.5, 5.5))\n",
    "#     plt.plot(df_acf, marker='.', color='b')\n",
    "#     plt.title('Autocorrelation function for DJIA')\n",
    "#     plt.xlabel('Lag in terms of number of trading days')\n",
    "#     plt.ylabel('Autocorrelation function')\n",
    "#     plt.savefig('acf.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df = ps.sqldf(\"\"\"select * from df order by dateval asc\"\"\")\n",
    "df = df.drop(\"dateval\",axis=1)\n",
    "df['log_y_tomorrow'] = df['log_y'].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(\"log_y_tomorrow\", axis=1).values\n",
    "y = df[\"log_y_tomorrow\"].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train=df.sample(frac=0.8,random_state=200)\n",
    "test=df.drop(train.index)\n",
    "X_train, y_train, X_test, y_test = train.drop([\"log_y_tomorrow\"], axis=1), \\\n",
    "train['log_y_tomorrow'], \\\n",
    "test.drop([\"log_y_tomorrow\"], axis=1), \\\n",
    "test['log_y_tomorrow']\n",
    "\n",
    "y = y_train\n",
    "X = X_train\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "select_top_20 = SelectKBest(score_func=chi2, k = 1)\n",
    "fit = select_top_20.fit(scaled_X,y.astype(int))\n",
    "features = fit.transform(X)\n",
    "mask = select_top_20.get_support()\n",
    "selected_best_features = X.columns[mask]\n",
    "\n",
    "from pandas import DataFrame\n",
    "from typing import Set, Any\n",
    "def remove_others(df: DataFrame, columns: Set[Any]):\n",
    "    cols_total: Set[Any] = set(df.columns)\n",
    "    diff: Set[Any] = cols_total - columns\n",
    "    df.drop(diff, axis=1, inplace=True)\n",
    "remove_others(X_train, set(selected_best_features))\n",
    "remove_others(X_test, set(selected_best_features))\n",
    "\n",
    "\n",
    "num_features = X_train.shape[1] - 1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=num_features)\n",
    "pca.fit(X_train)\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "count = 1\n",
    "n_components = None\n",
    "for k in var1:\n",
    "    if k > 80:\n",
    "        n_components = count\n",
    "        break\n",
    "    count += 1  \n",
    "pca = PCA(n_components=n_components)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# execute_model(model_number=1, X_train=X_train, \\\n",
    "#              X_test=X_test, y_train=y_train, \\\n",
    "#              y_test=y_test, num_features=num_features[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.22901587e+01,   1.23081470e+01,   5.37700318e-02, ...,\n",
       "         -1.79552674e-01,   5.53284836e-02,  -2.11962043e-02],\n",
       "       [  1.24337429e+01,   1.23108355e+01,   2.13353297e-02, ...,\n",
       "         -2.38959577e-01,   1.70185962e-03,  -8.09108393e-03],\n",
       "       [  1.24991083e+01,   1.23124227e+01,  -3.02880418e-03, ...,\n",
       "         -2.34964880e-01,  -4.12815703e-02,  -4.88925341e-02],\n",
       "       ..., \n",
       "       [  1.41617047e+01,   1.27204815e+01,   8.50958624e-02, ...,\n",
       "          1.07671810e-01,   1.74030589e-01,  -8.85389400e-02],\n",
       "       [  1.39892849e+01,   1.27215620e+01,   6.77742524e-02, ...,\n",
       "          2.46292702e-02,   1.60563990e-01,  -7.36303927e-02],\n",
       "       [  1.42721294e+01,   1.27226080e+01,   3.65899704e-02, ...,\n",
       "         -6.03733734e-02,   9.18591106e-02,   9.00499476e-02]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233] TEST: [234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9d063582af02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mexecute_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df = ps.sqldf(\"\"\"select * from df order by dateval asc\"\"\")\n",
    "df = df.drop(\"dateval\",axis=1)\n",
    "df['log_y_tomorrow'] = df['log_y'].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(\"log_y_tomorrow\", axis=1).values\n",
    "y = df[\"log_y_tomorrow\"].values\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "num_features = int((df.shape[1] - 1))\n",
    "for j in range(1, 4):\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        print(len(X))\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        pca = PCA(n_components=num_features)\n",
    "        pca.fit(X_train)\n",
    "        var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "        count = 1\n",
    "        n_components = None\n",
    "        for k in var1:\n",
    "            if k > 80:\n",
    "                n_components = count\n",
    "                break\n",
    "            count += 1        \n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit_transform(X_train)\n",
    "        pca.transform(X_test)\n",
    "        \n",
    "        execute_model(model_number=1, X_train=X_train, \\\n",
    "                     X_test=X_test, y_train=y_train, \\\n",
    "                     y_test=y_test, num_features=num_features[j])\n",
    "            \n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(model_number, X_train, X_test, y_train, y_test, num_features):\n",
    "    if model_number == 1:\n",
    "        model = Sequential() # linear stack of layers\n",
    "        model.add(Dense(1, input_shape=(num_features,))) # 1 output, j input\n",
    "        model.add(Dense(6, input_shape=(1, 12)))\n",
    "        model.compile(Adam(lr=0.8), 'mean_squared_error')\n",
    "        model.fit(X_train, y_train, epochs=40)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_y</th>\n",
       "      <th>2379_US_4497_5_X1.Value</th>\n",
       "      <th>2379_US_4497_5_X10.Value</th>\n",
       "      <th>2379_US_4497_5_X11.Value</th>\n",
       "      <th>2379_US_4497_5_X12.Value</th>\n",
       "      <th>2379_US_4497_5_X13.Value</th>\n",
       "      <th>2379_US_4497_5_X14.Value</th>\n",
       "      <th>2379_US_4497_5_X15.Value</th>\n",
       "      <th>2379_US_4497_5_X16.Value</th>\n",
       "      <th>2379_US_4497_5_X17.Value</th>\n",
       "      <th>...</th>\n",
       "      <th>2379_US_4497_5_X24.Value</th>\n",
       "      <th>2379_US_4497_5_X25.Value</th>\n",
       "      <th>2379_US_4497_5_X3.Value</th>\n",
       "      <th>2379_US_4497_5_X4.Value</th>\n",
       "      <th>2379_US_4497_5_X5.Value</th>\n",
       "      <th>2379_US_4497_5_X6.Value</th>\n",
       "      <th>2379_US_4497_5_X7.Value</th>\n",
       "      <th>2379_US_4497_5_X8.Value</th>\n",
       "      <th>2379_US_4497_5_X9.Value</th>\n",
       "      <th>log_y_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.290159</td>\n",
       "      <td>12.308147</td>\n",
       "      <td>0.053770</td>\n",
       "      <td>0.037802</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.044243</td>\n",
       "      <td>-0.040633</td>\n",
       "      <td>-0.143230</td>\n",
       "      <td>0.352553</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>-0.333071</td>\n",
       "      <td>0.718141</td>\n",
       "      <td>-0.257930</td>\n",
       "      <td>-0.223395</td>\n",
       "      <td>0.033521</td>\n",
       "      <td>-0.179553</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>-0.021196</td>\n",
       "      <td>12.433743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.433743</td>\n",
       "      <td>12.310836</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.022645</td>\n",
       "      <td>0.022428</td>\n",
       "      <td>-0.039489</td>\n",
       "      <td>-0.033009</td>\n",
       "      <td>0.168173</td>\n",
       "      <td>-0.324655</td>\n",
       "      <td>0.018119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>-0.307515</td>\n",
       "      <td>0.415349</td>\n",
       "      <td>-0.253495</td>\n",
       "      <td>-0.086582</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>-0.238960</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>-0.008091</td>\n",
       "      <td>12.499108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.499108</td>\n",
       "      <td>12.312423</td>\n",
       "      <td>-0.003029</td>\n",
       "      <td>0.109447</td>\n",
       "      <td>0.032251</td>\n",
       "      <td>-0.058462</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>-0.154604</td>\n",
       "      <td>0.346345</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046197</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.236314</td>\n",
       "      <td>-0.235246</td>\n",
       "      <td>0.136902</td>\n",
       "      <td>0.065279</td>\n",
       "      <td>-0.234965</td>\n",
       "      <td>-0.041282</td>\n",
       "      <td>-0.048893</td>\n",
       "      <td>12.520974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.520974</td>\n",
       "      <td>12.316396</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>0.076431</td>\n",
       "      <td>-0.083377</td>\n",
       "      <td>0.125738</td>\n",
       "      <td>-0.254959</td>\n",
       "      <td>-0.105489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.129859</td>\n",
       "      <td>0.581960</td>\n",
       "      <td>-0.224347</td>\n",
       "      <td>0.101392</td>\n",
       "      <td>-0.039138</td>\n",
       "      <td>-0.220550</td>\n",
       "      <td>-0.076108</td>\n",
       "      <td>0.132710</td>\n",
       "      <td>12.561623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.561623</td>\n",
       "      <td>12.321137</td>\n",
       "      <td>-0.040724</td>\n",
       "      <td>0.115593</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.143340</td>\n",
       "      <td>-0.237405</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>0.273819</td>\n",
       "      <td>-0.028431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058711</td>\n",
       "      <td>-0.004936</td>\n",
       "      <td>0.414952</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.094943</td>\n",
       "      <td>0.035220</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.073724</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>12.465485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_y  2379_US_4497_5_X1.Value  2379_US_4497_5_X10.Value  \\\n",
       "0  12.290159                12.308147                  0.053770   \n",
       "1  12.433743                12.310836                  0.021335   \n",
       "2  12.499108                12.312423                 -0.003029   \n",
       "3  12.520974                12.316396                 -0.026501   \n",
       "4  12.561623                12.321137                 -0.040724   \n",
       "\n",
       "   2379_US_4497_5_X11.Value  2379_US_4497_5_X12.Value  \\\n",
       "0                  0.037802                  0.003591   \n",
       "1                  0.022645                  0.022428   \n",
       "2                  0.109447                  0.032251   \n",
       "3                  0.073352                 -0.005201   \n",
       "4                  0.115593                  0.003768   \n",
       "\n",
       "   2379_US_4497_5_X13.Value  2379_US_4497_5_X14.Value  \\\n",
       "0                  0.044243                 -0.040633   \n",
       "1                 -0.039489                 -0.033009   \n",
       "2                 -0.058462                  0.000721   \n",
       "3                  0.076431                 -0.083377   \n",
       "4                  0.143340                 -0.237405   \n",
       "\n",
       "   2379_US_4497_5_X15.Value  2379_US_4497_5_X16.Value  \\\n",
       "0                 -0.143230                  0.352553   \n",
       "1                  0.168173                 -0.324655   \n",
       "2                 -0.154604                  0.346345   \n",
       "3                  0.125738                 -0.254959   \n",
       "4                 -0.037265                  0.273819   \n",
       "\n",
       "   2379_US_4497_5_X17.Value       ...        2379_US_4497_5_X24.Value  \\\n",
       "0                  0.003618       ...                        0.005489   \n",
       "1                  0.018119       ...                        0.031233   \n",
       "2                  0.024366       ...                        0.046197   \n",
       "3                 -0.105489       ...                        0.054434   \n",
       "4                 -0.028431       ...                        0.058711   \n",
       "\n",
       "   2379_US_4497_5_X25.Value  2379_US_4497_5_X3.Value  2379_US_4497_5_X4.Value  \\\n",
       "0                 -0.333071                 0.718141                -0.257930   \n",
       "1                 -0.307515                 0.415349                -0.253495   \n",
       "2                  0.021096                 0.236314                -0.235246   \n",
       "3                  0.129859                 0.581960                -0.224347   \n",
       "4                 -0.004936                 0.414952                -0.208148   \n",
       "\n",
       "   2379_US_4497_5_X5.Value  2379_US_4497_5_X6.Value  2379_US_4497_5_X7.Value  \\\n",
       "0                -0.223395                 0.033521                -0.179553   \n",
       "1                -0.086582                 0.018053                -0.238960   \n",
       "2                 0.136902                 0.065279                -0.234965   \n",
       "3                 0.101392                -0.039138                -0.220550   \n",
       "4                -0.094943                 0.035220                -0.177225   \n",
       "\n",
       "   2379_US_4497_5_X8.Value  2379_US_4497_5_X9.Value  log_y_tomorrow  \n",
       "0                 0.055328                -0.021196       12.433743  \n",
       "1                 0.001702                -0.008091       12.499108  \n",
       "2                -0.041282                -0.048893       12.520974  \n",
       "3                -0.076108                 0.132710       12.561623  \n",
       "4                -0.073724                -0.002946       12.465485  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df['log_y_tomorrow'] = df['log_y'].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(['log_y_tomorrow'], axis = 1).values\n",
    "y = df['log_y_tomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8a88c318cf86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcv_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[1;32m   1173\u001b[0m                          order=\"C\")\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/keras_timeseries/venv/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m             'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "models = []\n",
    "models.append((\"LR\",LogisticRegression()))\n",
    "models.append((\"KNN\",KNeighborsRegressor()))\n",
    "models.append((\"DT\",DecisionTreeRegressor()))\n",
    "models.append((\"SVR\",SVR()))\n",
    "models.append((\"AdaBoost\",AdaBoostRegressor(n_estimators=500, random_state=2)))\n",
    "models.append((\"RandomForestRegressor\",RandomForestRegressor(n_estimators = 1000, max_features=\"log2\", min_samples_leaf=5, criterion=\"mse\", \n",
    "                                        bootstrap = True,random_state=2)))\n",
    "models.append((\"XGBRegressor\",make_pipeline(\n",
    "    StackingEstimator(estimator=RidgeCV()),\n",
    "    XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=13, n_estimators=100, nthread=1, subsample=0.55)\n",
    ")))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=5, random_state=22)\n",
    "    cv_result = cross_val_score(model,X_train,y_train, cv = kfold, scoring='neg_mean_squared_error')\n",
    "    names.append(name)\n",
    "    results.append(cv_result)\n",
    "for i in range(len(names)):\n",
    "    print(names[i],results[i].mean())\n",
    "ax = sns.boxplot(data=results)\n",
    "ax.set_xticklabels(names, rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df.fillna(0)\n",
    "df_temp = df_temp.replace([np.inf, -np.inf], np.nan)\n",
    "df_temp.isnull().values.any()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "DATE_FIELD = \"dateval\" ### Change\n",
    "\n",
    "unique_field = [DATE_FIELD]\n",
    "ps.sqldf(\"select count(*), count(distinct {}) from df\".format(\",\".join(unique_field)), locals())\n",
    "\n",
    "ps.sqldf(\"select min({}) AS min_date, max({}) AS max_date, count(*) AS days, (julianday(max({})) - julianday(min({}))) + 1 AS date_diff__should_match_days from df\".format(DATE_FIELD,DATE_FIELD,DATE_FIELD,DATE_FIELD), locals())\n",
    "\n",
    "\n",
    "\n",
    "df['x'] = df.index\n",
    "df = df.set_index(DATE_FIELD)\n",
    "df.iloc[0:4]\n",
    "\n",
    "TODAY_AMOUNT = \"log_y\" ### Change\n",
    "\n",
    "df.shape\n",
    "\n",
    "TARGET_NAME = 'tomorrow_{}'.format(TODAY_AMOUNT)\n",
    "df[TARGET_NAME] = df[TODAY_AMOUNT].shift(-1)\n",
    "df.drop(df.tail(1).index,inplace=True)\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.iloc[0:4]\n",
    "\n",
    "ax = sns.tsplot(data=df[TODAY_AMOUNT])\n",
    "\n",
    "##### Remove trailing 0's when 0's only occur at the end\n",
    "\n",
    "result = ps.sqldf(\"select min({}) min_date from df where {} = 0\".format(DATE_FIELD, TODAY_AMOUNT), locals())\n",
    "result\n",
    "\n",
    "result.iloc[0][0]\n",
    "\n",
    "df = df[df.index < result.iloc[0][0]]\n",
    "\n",
    "ax = sns.tsplot(data=df[TODAY_AMOUNT])\n",
    "\n",
    "df = df.fillna(method='ffill')\n",
    "\n",
    "ax = sns.tsplot(data=df[TODAY_AMOUNT])\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 26\n",
    "\n",
    "axs2 = list(itertools.repeat(None, N))\n",
    "\n",
    "fig, ax1 = plt.subplots(9,3, figsize=(25,25))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.5)\n",
    "fig.tight_layout()\n",
    "\n",
    "axs = ax1.ravel()\n",
    "for i in range(1, N):\n",
    "    column_name = \"2379_US_4497_5_X{}.Value\".format(i)\n",
    "    axs[i].plot(df['x'], df[column_name], 'b-')\n",
    "    axs[i].set_title(column_name)  \n",
    "    axs2[i] = axs[i].twinx()\n",
    "    axs2[i].plot(df['x'], df[TODAY_AMOUNT], 'r-')\n",
    "    fig.tight_layout()\n",
    "plt.savefig('ssa.png', format='png', dpi=300)\n",
    "\n",
    "df2 = df[[\"x\", TODAY_AMOUNT,TARGET_NAME, \"2379_US_4497_5_X1.Value\", \"2379_US_4497_5_X2.Value\"]]\n",
    "\n",
    "df2.info()\n",
    "\n",
    "lag = range(0,31)\n",
    "df_acf = []\n",
    "for l in lag:\n",
    "    df_acf.append(df2[TARGET_NAME].autocorr(l))\n",
    "plt.figure(figsize=(5.5, 5.5))\n",
    "plt.plot(df_acf, marker='.', color='b')\n",
    "plt.title('Autocorrelation function')\n",
    "plt.xlabel('Lag in terms of days')\n",
    "plt.ylabel('Autocorrelation function')\n",
    "plt.savefig('acf.png', format='png', dpi=300)\n",
    "\n",
    "#Plot autocorrelation and confidence intervals using the plot_acf function\n",
    "plt.figure(figsize=(5.5, 5.5))\n",
    "plot_acf(df2[TARGET_NAME], lags=20)\n",
    "plt.savefig('acf_ci.png', format='png', dpi=300)\n",
    "\n",
    "#Plot partial autocorrelation and confidence intervals using the plot_acf function\n",
    "plt.figure(figsize=(5.5, 5.5))\n",
    "plot_pacf(df2[TARGET_NAME], lags=20)\n",
    "plt.savefig('pacf_ci.png', format='png', dpi=300)\n",
    "\n",
    "### Lags to use\n",
    "- I'll try 7 lags\n",
    "\n",
    "df2.shape\n",
    "\n",
    "for s in range(1,8):\n",
    "    original_columns = [TODAY_AMOUNT, \"2379_US_4497_5_X1.Value\", \"2379_US_4497_5_X2.Value\"]\n",
    "    for original_column in original_columns:\n",
    "        shift_column = 'shift_{}_{}'.format(s, original_column)\n",
    "        df2[shift_column] = df2[original_column].shift(s)\n",
    "df2 = df2.dropna()\n",
    "\n",
    "df2.shape\n",
    "\n",
    "df2.iloc[0:4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        scaler2 = MinMaxScaler()\n",
    "        X_scaled_nonnegative = scaler2.fit_transform(X[train_index])\n",
    "        \n",
    "        select_top_k = SelectKBest(score_func=chi2, k = num_features[j])\n",
    "        fit = select_top_k.fit(X_train, y_train.astype('int'))\n",
    "        features = fit.transform(X_train)\n",
    "        mask = select_top_k.get_support()\n",
    "        selected_best_features = X_train.columns[mask]\n",
    "        def remove_others(df: DataFrame, columns: Set[Any]):\n",
    "            cols_total: Set[Any] = set(df.columns)\n",
    "            diff: Set[Any] = cols_total - columns\n",
    "            df.drop(diff, axis=1, inplace=True)\n",
    "        remove_others(X_train, set(selected_best_features))\n",
    "        remove_others(X_test, set(selected_best_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_timeseries",
   "language": "python",
   "name": "keras_timeseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
